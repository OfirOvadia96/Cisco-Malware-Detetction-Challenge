{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np # Support for large arrays and matrices, along with high-level mathematical functions.\n",
    "import seaborn as sns # Graphing/Plotting module.\n",
    "import pandas as pd # CSV handling with operations on tabular data.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from ast import literal_eval # Transform/Parse a string-list into a proper list.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:  (40738, 92)\n",
      "df_test.shape:  (11640, 89)\n",
      "df_val.shape:  (5820, 89)\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "''' \n",
    "There are 2 datasets available for you to use - \n",
    "1. 'mta' \n",
    "2. 'ustc'\n",
    "Make sure that \n",
    "the path to the .csv files is correct. the following code loads the data from .csv file\n",
    "into a DataFrame.\n",
    "'''\n",
    "\n",
    "dataset_type = 'ustc' # 'ustc' or 'mta'\n",
    "\n",
    "filepath = f'./datasets/{dataset_type}/xy_train.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "filepath_test = f'./datasets/{dataset_type}/x_test.csv'\n",
    "df_test = pd.read_csv(filepath_test)\n",
    "\n",
    "filepath_val = f'./datasets/{dataset_type}/x_val.csv'\n",
    "df_val = pd.read_csv(filepath_val)\n",
    "\n",
    "print(\"df.shape: \",df.shape)\n",
    "print(\"df_test.shape: \",df_test.shape)\n",
    "print(\"df_val.shape: \",df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - After:  (40738, 81)\n",
      "Test - After:  (11640, 78)\n",
      "Val - After:  (5820, 78)\n"
     ]
    }
   ],
   "source": [
    "#Drop the columns where the values are equal in all\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        # print(\"col drop: \",col)\n",
    "        df = df.drop(col,axis=1)\n",
    "\n",
    "print(\"Train - After: \" ,df.shape)\n",
    "\n",
    "#------------------------------------\n",
    "\n",
    "#Drop the columns where the values are equal in all\n",
    "for col in df_test.columns:\n",
    "    if len(df_test[col].unique()) == 1:\n",
    "        # print(\"col drop: \",col)\n",
    "        df_test = df_test.drop(col,axis=1)\n",
    "\n",
    "print(\"Test - After: \" ,df_test.shape)\n",
    "\n",
    "#-----------------------------------------\n",
    "\n",
    "#Drop the columns where the values are equal in all\n",
    "for col in df_val.columns:\n",
    "    if len(df_val[col].unique()) == 1:\n",
    "        # print(\"col drop: \",col)\n",
    "        df_val = df_val.drop(col,axis=1)\n",
    "\n",
    "print(\"Val - After: \" ,df_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:  (40738, 54)\n",
      "df_test.shape:  (11640, 54)\n",
      "df_val.shape:  (5820, 54)\n"
     ]
    }
   ],
   "source": [
    "y = df['malware_family']\n",
    "\n",
    "df.drop('src_ip', inplace=True, axis=1)\n",
    "df.drop('dst_ip', inplace=True, axis=1)\n",
    "df.drop('src_mac', inplace=True, axis=1)\n",
    "df.drop('src_oui', inplace=True, axis=1)\n",
    "df.drop('dst_mac', inplace=True, axis=1)\n",
    "df.drop('dst_oui', inplace=True, axis=1)\n",
    "df.drop('application_name', inplace=True, axis=1)\n",
    "df.drop('application_category_name', inplace=True, axis=1)\n",
    "df.drop('requested_server_name', inplace=True, axis=1)\n",
    "df.drop('client_fingerprint', inplace=True, axis=1)\n",
    "df.drop('server_fingerprint', inplace=True, axis=1)\n",
    "df.drop('content_type', inplace=True, axis=1)\n",
    "df.drop('user_agent', inplace=True, axis=1)\n",
    "df.drop('udps.protocol_header_fields', inplace=True, axis=1)\n",
    "df.drop('udps.n_bytes_per_packet', inplace=True, axis=1)\n",
    "df.drop('udps.stnn_image', inplace=True, axis=1)\n",
    "df.drop('udps.n_bytes', inplace=True, axis=1)\n",
    "df.drop('file_name', inplace=True, axis=1)\n",
    "df.drop('malware_family', inplace=True, axis=1)\n",
    "df.drop('label', inplace=True, axis=1)\n",
    "\n",
    "df.drop(['src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms','src_port','dst_port'], inplace=True, axis=1)\n",
    "\n",
    "#-----------Test-------------\n",
    "\n",
    "df_test.drop('src_ip', inplace=True, axis=1)\n",
    "df_test.drop('dst_ip', inplace=True, axis=1)\n",
    "df_test.drop('src_mac', inplace=True, axis=1)\n",
    "df_test.drop('src_oui', inplace=True, axis=1)\n",
    "df_test.drop('dst_mac', inplace=True, axis=1)\n",
    "df_test.drop('dst_oui', inplace=True, axis=1)\n",
    "df_test.drop('application_name', inplace=True, axis=1)\n",
    "df_test.drop('application_category_name', inplace=True, axis=1)\n",
    "df_test.drop('requested_server_name', inplace=True, axis=1)\n",
    "df_test.drop('client_fingerprint', inplace=True, axis=1)\n",
    "df_test.drop('server_fingerprint', inplace=True, axis=1)\n",
    "df_test.drop('content_type', inplace=True, axis=1)\n",
    "df_test.drop('user_agent', inplace=True, axis=1)\n",
    "df_test.drop('udps.protocol_header_fields', inplace=True, axis=1)\n",
    "df_test.drop('udps.n_bytes_per_packet', inplace=True, axis=1)\n",
    "df_test.drop('udps.stnn_image', inplace=True, axis=1)\n",
    "df_test.drop('udps.n_bytes', inplace=True, axis=1)\n",
    "\n",
    "df_test.drop(['src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms','src_port','dst_port'], inplace=True, axis=1)\n",
    "\n",
    "#-----------Validation-------------\n",
    "\n",
    "df_val.drop('src_ip', inplace=True, axis=1)\n",
    "df_val.drop('dst_ip', inplace=True, axis=1)\n",
    "df_val.drop('src_mac', inplace=True, axis=1)\n",
    "df_val.drop('src_oui', inplace=True, axis=1)\n",
    "df_val.drop('dst_mac', inplace=True, axis=1)\n",
    "df_val.drop('dst_oui', inplace=True, axis=1)\n",
    "df_val.drop('application_name', inplace=True, axis=1)\n",
    "df_val.drop('application_category_name', inplace=True, axis=1)\n",
    "df_val.drop('requested_server_name', inplace=True, axis=1)\n",
    "df_val.drop('client_fingerprint', inplace=True, axis=1)\n",
    "df_val.drop('server_fingerprint', inplace=True, axis=1)\n",
    "df_val.drop('content_type', inplace=True, axis=1)\n",
    "df_val.drop('user_agent', inplace=True, axis=1)\n",
    "df_val.drop('udps.protocol_header_fields', inplace=True, axis=1)\n",
    "df_val.drop('udps.n_bytes_per_packet', inplace=True, axis=1)\n",
    "df_val.drop('udps.stnn_image', inplace=True, axis=1)\n",
    "df_val.drop('udps.n_bytes', inplace=True, axis=1)\n",
    "\n",
    "df_val.drop(['src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms','src_port','dst_port'], inplace=True, axis=1)\n",
    "# FOR ustc\n",
    "df.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "df.fillna(0)\n",
    "df_test.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "df_test.fillna(0)\n",
    "df_val.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "df_val.fillna(0)\n",
    "\n",
    "X = df\n",
    "print(\"df.shape: \",df.shape)\n",
    "print(\"df_test.shape: \",df_test.shape)\n",
    "print(\"df_val.shape: \",df_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "\n",
    "model_type = \"Random Forest Classifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------xy_train------------------\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Actual class predictions\n",
    "y_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------y_test------------------\n",
    "\n",
    "# # Fit on all train data\n",
    "model.fit(X,y)\n",
    "\n",
    "# Actual class predictions\n",
    "y_predictions = model.predict(df_test)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "np.savetxt('predictions_test_'+ dataset_type +'.txt', enc.fit_transform(y_predictions), fmt='%2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------y_val------------------\n",
    "\n",
    "# Fit on all train data\n",
    "model.fit(X,y)\n",
    "\n",
    "# Actual class predictions\n",
    "y_predictions = model.predict(df_val)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "np.savetxt('predictions_val_'+ dataset_type +'.txt', enc.fit_transform(y_predictions), fmt='%2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of ' + model_type + ' on test set: {:.5f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Confusion Matrix\n",
    "true_labels = y_test\n",
    "confusion_matrix = confusion_matrix(y_test, y_predictions)\n",
    "\n",
    "heatmap = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "                      xticklabels=np.unique(true_labels), \n",
    "                      yticklabels=np.unique(true_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# K FOLD - CROSS VALIDATION\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,\n",
    "    random_state=0)\n",
    "scores = cross_val_score(clf, df, y, cv=5)\n",
    "print(\"DecisionTreeClassifier - scores.mean(): \",scores.mean())\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, df, y, cv=5)\n",
    "print(\"RandomForestClassifier - scores.mean(): \",scores.mean())\n",
    "\n",
    "\n",
    "# n_estimators - Number of Tree (More its better)\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, df, y, cv=5)\n",
    "print(\"ExtraTreesClassifier - scores.mean(): \",scores.mean())\n",
    "\n",
    "\n",
    "# AdaBoostClassifier\n",
    "# n_estimators = 100 weak learners\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, df, y, cv=5)\n",
    "print(\"AdaBoostClassifier - scores.mean(): \",scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, df, y, cv=5)\n",
    "print(\"GradientBoostingClassifier - scores.mean(): \",scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9848298951 (+/- 0.0007180153) [Decision Tree]\n",
      "Accuracy: 0.9882909937 (+/- 0.0010319965) [Random Forest]\n",
      "Accuracy: 0.6558746834 (+/- 0.0680654397) [AdaBoost]\n",
      "Accuracy: 0.8278266245 (+/- 0.0039243828) [GradientBoosting]\n",
      "Accuracy: 0.9859835946 (+/- 0.0005883054) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=42)\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "clf3 = AdaBoostClassifier(n_estimators=20)\n",
    "clf4 = GradientBoostingClassifier(n_estimators=20, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2), ('ab', clf3), ('gb', clf4)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['Decision Tree', 'Random Forest', 'AdaBoost', 'GradientBoosting','Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.10f (+/- %0.10f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "116f2652fbe7bd71c42006778ec45c04a73572d75cb877527c86e96111d40ce9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
