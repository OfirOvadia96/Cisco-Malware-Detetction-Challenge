{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np # Support for large arrays and matrices, along with high-level mathematical functions.\n",
    "import seaborn as sns # Graphing/Plotting module.\n",
    "import pandas as pd # CSV handling with operations on tabular data.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from ast import literal_eval # Transform/Parse a string-list into a proper list.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "plt.rc(\"font\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "''' \n",
    "There are 3 datasets available for you to use:\n",
    "1. 'mta' \n",
    "2. 'ustc'\n",
    "3. 'zero'\n",
    "'''\n",
    "\n",
    "dataset_type = 'ustc' # 'mta' or 'ustc' or 'zero'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape:  (40738, 92)\n"
     ]
    }
   ],
   "source": [
    "# xy_train\n",
    "filepath = f'./datasets/{dataset_type}/xy_train.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "print(\"df_train.shape: \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test.shape:  (11640, 89)\n"
     ]
    }
   ],
   "source": [
    "# x_test\n",
    "filepath_test = f'./datasets/{dataset_type}/x_test.csv'\n",
    "df_test = pd.read_csv(filepath_test)\n",
    "print(\"df_test.shape: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val.shape:  (5820, 89)\n"
     ]
    }
   ],
   "source": [
    "#x_val\n",
    "filepath_val = f'./datasets/{dataset_type}/x_val.csv'\n",
    "df_val = pd.read_csv(filepath_val)\n",
    "print(\"df_val.shape: \",df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProccessing & Clear unnecessary data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - After:  (40738, 81)\n"
     ]
    }
   ],
   "source": [
    "#Train - Drop the columns where the values are equal in all\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        # print(\"col drop: \",col)\n",
    "        df = df.drop(col,axis=1)\n",
    "\n",
    "print(\"Train - After: \" ,df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - After:  (11640, 78)\n"
     ]
    }
   ],
   "source": [
    "#Test - Drop the columns where the values are equal in all\n",
    "for col in df_test.columns:\n",
    "    if len(df_test[col].unique()) == 1:\n",
    "        # print(\"col drop: \",col)\n",
    "        df_test = df_test.drop(col,axis=1)\n",
    "\n",
    "print(\"Test - After: \" ,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - After:  (5820, 78)\n"
     ]
    }
   ],
   "source": [
    "#Validation - Drop the columns where the values are equal in all\n",
    "for col in df_val.columns:\n",
    "    if len(df_val[col].unique()) == 1:\n",
    "        # print(\"col drop: \",col)\n",
    "        df_val = df_val.drop(col,axis=1)\n",
    "\n",
    "print(\"Val - After: \" ,df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "There are 2 type of labels:\n",
    "1. 'label': Binary labelling of {benign, malware} \n",
    "2. 'malware_family': Multi-class labelling of benign and malware families.\n",
    "'''\n",
    "\n",
    "label_type = 'malware_family' # or 'malware_family' for malware classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:  (40738, 56)\n"
     ]
    }
   ],
   "source": [
    "# Drop string & overfiting feature from xy_train\n",
    "\n",
    "y = df[label_type]\n",
    "\n",
    "df.drop('src_ip', inplace=True, axis=1)\n",
    "df.drop('dst_ip', inplace=True, axis=1)\n",
    "df.drop('src_mac', inplace=True, axis=1)\n",
    "df.drop('src_oui', inplace=True, axis=1)\n",
    "df.drop('dst_mac', inplace=True, axis=1)\n",
    "df.drop('dst_oui', inplace=True, axis=1)\n",
    "df.drop('requested_server_name', inplace=True, axis=1)\n",
    "df.drop('client_fingerprint', inplace=True, axis=1)\n",
    "df.drop('server_fingerprint', inplace=True, axis=1)\n",
    "df.drop('content_type', inplace=True, axis=1)\n",
    "df.drop('user_agent', inplace=True, axis=1)\n",
    "df.drop('udps.protocol_header_fields', inplace=True, axis=1)\n",
    "df.drop('udps.n_bytes_per_packet', inplace=True, axis=1)\n",
    "df.drop('udps.stnn_image', inplace=True, axis=1)\n",
    "df.drop('udps.n_bytes', inplace=True, axis=1)\n",
    "df.drop('label', inplace=True, axis=1)\n",
    "df.drop('malware_family', inplace=True, axis=1)\n",
    "\n",
    "# Feature of Overfiting\n",
    "df.drop('bidirectional_last_seen_ms', inplace=True, axis=1)\n",
    "df.drop('bidirectional_first_seen_ms', inplace=True, axis=1)\n",
    "df.drop(['src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms','src_port','dst_port'], inplace=True, axis=1)\n",
    "\n",
    "print(\"df.shape: \",df.shape)\n",
    "\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:  (40738, 53)\n"
     ]
    }
   ],
   "source": [
    "#Only in mta & ustc\n",
    "df.drop('file_name', inplace=True, axis=1)\n",
    "df.drop('application_name', inplace=True, axis=1)\n",
    "df.drop('application_category_name', inplace=True, axis=1)\n",
    "\n",
    "print(\"df.shape: \",df.shape)\n",
    "\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test.shape:  (11640, 53)\n"
     ]
    }
   ],
   "source": [
    "# Drop string & overfiting feature from x_test df\n",
    "\n",
    "df_test.drop('src_ip', inplace=True, axis=1)\n",
    "df_test.drop('dst_ip', inplace=True, axis=1)\n",
    "df_test.drop('src_mac', inplace=True, axis=1)\n",
    "df_test.drop('src_oui', inplace=True, axis=1)\n",
    "df_test.drop('dst_mac', inplace=True, axis=1)\n",
    "df_test.drop('dst_oui', inplace=True, axis=1)\n",
    "df_test.drop('application_name', inplace=True, axis=1)\n",
    "df_test.drop('application_category_name', inplace=True, axis=1)\n",
    "df_test.drop('requested_server_name', inplace=True, axis=1)\n",
    "df_test.drop('client_fingerprint', inplace=True, axis=1)\n",
    "df_test.drop('server_fingerprint', inplace=True, axis=1)\n",
    "df_test.drop('content_type', inplace=True, axis=1)\n",
    "df_test.drop('user_agent', inplace=True, axis=1)\n",
    "df_test.drop('udps.protocol_header_fields', inplace=True, axis=1)\n",
    "df_test.drop('udps.n_bytes_per_packet', inplace=True, axis=1)\n",
    "df_test.drop('udps.stnn_image', inplace=True, axis=1)\n",
    "df_test.drop('udps.n_bytes', inplace=True, axis=1)\n",
    "\n",
    "# Feature of Overfiting\n",
    "df_test.drop('bidirectional_last_seen_ms', inplace=True, axis=1)\n",
    "df_test.drop('bidirectional_first_seen_ms', inplace=True, axis=1)\n",
    "df_test.drop(['src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms','src_port','dst_port'], inplace=True, axis=1)\n",
    "\n",
    "print(\"df_test.shape: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val.shape:  (5820, 55)\n"
     ]
    }
   ],
   "source": [
    "# Drop string & overfiting feature from x_validation df\n",
    "\n",
    "df_val.drop('src_ip', inplace=True, axis=1)\n",
    "df_val.drop('dst_ip', inplace=True, axis=1)\n",
    "df_val.drop('src_mac', inplace=True, axis=1)\n",
    "df_val.drop('src_oui', inplace=True, axis=1)\n",
    "df_val.drop('dst_mac', inplace=True, axis=1)\n",
    "df_val.drop('dst_oui', inplace=True, axis=1)\n",
    "df_val.drop('requested_server_name', inplace=True, axis=1)\n",
    "df_val.drop('client_fingerprint', inplace=True, axis=1)\n",
    "df_val.drop('server_fingerprint', inplace=True, axis=1)\n",
    "df_val.drop('content_type', inplace=True, axis=1)\n",
    "df_val.drop('user_agent', inplace=True, axis=1)\n",
    "df_val.drop('udps.protocol_header_fields', inplace=True, axis=1)\n",
    "df_val.drop('udps.n_bytes_per_packet', inplace=True, axis=1)\n",
    "df_val.drop('udps.stnn_image', inplace=True, axis=1)\n",
    "df_val.drop('udps.n_bytes', inplace=True, axis=1)\n",
    "\n",
    "# Feature of Overfiting\n",
    "df_val.drop('bidirectional_last_seen_ms', inplace=True, axis=1)\n",
    "df_val.drop('bidirectional_first_seen_ms', inplace=True, axis=1)\n",
    "df_val.drop(['src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms','src_port','dst_port'], inplace=True, axis=1)\n",
    "\n",
    "print(\"df_val.shape: \",df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val.shape:  (5820, 53)\n"
     ]
    }
   ],
   "source": [
    "#Only in mta & ustc\n",
    "df_val.drop('application_name', inplace=True, axis=1)\n",
    "df_val.drop('application_category_name', inplace=True, axis=1)\n",
    "\n",
    "print(\"df_val.shape: \",df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ustc\n",
    "\n",
    "df.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "df.fillna(0)\n",
    "df_test.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "df_test.fillna(0)\n",
    "df_val.drop('Unnamed: 0.1', inplace=True, axis=1)\n",
    "df_val.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .  bidirectional_duration_ms\n",
      "2 .  bidirectional_packets\n",
      "3 .  bidirectional_bytes\n",
      "4 .  src2dst_duration_ms\n",
      "5 .  src2dst_packets\n",
      "6 .  src2dst_bytes\n",
      "7 .  dst2src_duration_ms\n",
      "8 .  dst2src_packets\n",
      "9 .  dst2src_bytes\n",
      "10 .  bidirectional_max_ps\n",
      "11 .  src2dst_max_ps\n",
      "12 .  dst2src_mean_ps\n",
      "13 .  dst2src_max_ps\n",
      "14 .  bidirectional_min_piat_ms\n",
      "15 .  bidirectional_mean_piat_ms\n",
      "16 .  bidirectional_stddev_piat_ms\n",
      "17 .  bidirectional_max_piat_ms\n",
      "18 .  src2dst_min_piat_ms\n",
      "19 .  src2dst_mean_piat_ms\n",
      "20 .  src2dst_stddev_piat_ms\n",
      "21 .  src2dst_max_piat_ms\n",
      "22 .  dst2src_min_piat_ms\n",
      "23 .  dst2src_mean_piat_ms\n",
      "24 .  dst2src_stddev_piat_ms\n",
      "25 .  dst2src_max_piat_ms\n",
      "26 .  bidirectional_ack_packets\n",
      "27 .  bidirectional_psh_packets\n",
      "28 .  src2dst_ack_packets\n",
      "29 .  dst2src_ack_packets\n",
      "30 .  udps.handshake_packets_duration\n"
     ]
    }
   ],
   "source": [
    "# Univariate feature selection\n",
    "\n",
    "#Select features according to the k highest scores.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X_new = SelectKBest(chi2, k=30).fit(X, y)\n",
    "\n",
    "\n",
    "cols = X_new.get_support(indices=True)\n",
    "features_df_new = X.iloc[:,cols]\n",
    "\n",
    "i = 1\n",
    "for col in features_df_new.columns:\n",
    "    print(i,\". \",col)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40738, 30)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features_df_new\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11640, 30)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean feature from df_test like x_new\n",
    "\n",
    "list_df_test = df_test.columns.to_list()\n",
    "\n",
    "for col in list_df_test:\n",
    "    if(col not in features_df_new):\n",
    "         df_test = df_test.drop(col,axis=1)\n",
    "\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5820, 30)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean feature from df_val like x_new\n",
    "\n",
    "list_df_val = df_val.columns.to_list()\n",
    "\n",
    "for col in list_df_val:\n",
    "    if(col not in features_df_new):\n",
    "         df_val = df_val.drop(col,axis=1)\n",
    "\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "\n",
    "model_type = \"Random Forest Classifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------xy_train------------------\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Actual class predictions\n",
    "y_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------y_test------------------\n",
    "\n",
    "# # Fit on all train data\n",
    "model.fit(X,y)\n",
    "\n",
    "# Actual class predictions\n",
    "y_predictions = model.predict(df_test)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "np.savetxt('predictions_test_'+ label_type +'_'+ dataset_type +'.txt', enc.fit_transform(y_predictions), fmt='%2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------y_val------------------\n",
    "\n",
    "# Fit on all train data\n",
    "model.fit(X,y)\n",
    "\n",
    "# Actual class predictions\n",
    "y_predictions = model.predict(df_val)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "np.savetxt('predictions_val_' + label_type + '_'+ dataset_type +'.txt', enc.fit_transform(y_predictions), fmt='%2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of ' + model_type + ' on test set: {:.5f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Confusion Matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_predictions)\n",
    "# print(confusion_matrix)\n",
    "\n",
    "true_labels = y_test\n",
    "heatmap = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "                      xticklabels=np.unique(true_labels), \n",
    "                      yticklabels=np.unique(true_labels)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "116f2652fbe7bd71c42006778ec45c04a73572d75cb877527c86e96111d40ce9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
